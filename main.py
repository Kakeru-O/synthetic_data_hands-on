import marimo

__generated_with = "0.19.9"
app = marimo.App(width="medium")


@app.cell
def _():
    import marimo as mo
    from mostlyai.sdk import MostlyAI
    import pandas as pd
    import altair as alt
    from sklearn.neighbors import NearestNeighbors
    from sklearn.preprocessing import StandardScaler
    import numpy as np
    from pathlib import Path

    return MostlyAI, NearestNeighbors, Path, StandardScaler, alt, mo, np, pd


@app.cell
def _(mo):
    mo.md(r"""
    # åˆæˆãƒ‡ãƒ¼ã‚¿ãƒãƒ³ã‚ºã‚ªãƒ³ï¼šMarimoã¨MostlyAIã§ä½œã‚‹å®‰å…¨ãªãƒ‡ãƒ¼ã‚¿å…±æœ‰åŸºç›¤

    ãƒãƒ¼ã‚±ãƒ†ã‚£ãƒ³ã‚°éƒ¨é–€ãŒã€ã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³ã®ã‚¿ãƒ¼ã‚²ãƒƒãƒˆç²¾åº¦å‘ä¸Šã®ãŸã‚ã€é¡§å®¢ãƒ‡ãƒ¼ã‚¿ã‚’å¤–éƒ¨ã«æä¾›ã—ã€ãƒ‡ãƒ¼ã‚¿åˆ†æã—ãŸã„ã¨è€ƒãˆã¦ã„ã¾ã™ã€‚
    ã—ã‹ã—ã€æ³•å‹™éƒ¨é–€ã‹ã‚‰ã¯ã€Œå€‹äººæƒ…å ±ä¿è­·ï¼ˆGDPR/APPIï¼‰ã€ã®è¦³ç‚¹ã‹ã‚‰ã‚¹ãƒˆãƒƒãƒ—ãŒã‹ã‹ã£ã¦ã„ã¾ã™ã€‚

    **ã‚ãªãŸã®ãƒŸãƒƒã‚·ãƒ§ãƒ³:** å…ƒã®é¡§å®¢ãƒ‡ãƒ¼ã‚¿ã®çµ±è¨ˆçš„æ€§è³ªã‚’ç¶­æŒã—ã¤ã¤ã€**å®Ÿåœ¨ã™ã‚‹å€‹äººã‚’ä¸€åˆ‡å«ã¾ãªã„**åˆæˆãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½œæˆã—ã€
    ãƒ‡ãƒ¼ã‚¿ã‚’å®‰å…¨ã«å…±æœ‰ã§ãã‚‹ã“ã¨ã‚’æ³•å‹™éƒ¨é–€ã«è¨¼æ˜ã—ã¾ã—ã‚‡ã†ã€‚
    """)
    return


@app.cell
def _(mo):
    mo.md(r"""
    ---

    ## Step 1: ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ ("The Dangerous Data")

    UCI Machine Learning Repository ã‹ã‚‰ "Bank Marketing" ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’å–å¾—ãƒ»èª­ã¿è¾¼ã¿ã¾ã™ã€‚

    > âš ï¸ ã“ã®ãƒ‡ãƒ¼ã‚¿ã«ã¯é¡§å®¢ã®å¹´é½¢ã€è·æ¥­ã€æ®‹é«˜ãªã©ã®**æ©Ÿå¯†å±æ€§**ãŒå«ã¾ã‚Œã¦ã„ã‚‹ã¨æƒ³å®šã—ã¦ãã ã•ã„ã€‚
    > **ã“ã®ã¾ã¾ã®å½¢å¼ã§ã¯ã€ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼ä¿è­·ã®è¦³ç‚¹ã‹ã‚‰å¤–éƒ¨ã«æä¾›ã™ã‚‹ã“ã¨ã¯ã§ãã¾ã›ã‚“ã€‚**
    """)
    return


@app.cell
def _(Path, pd):
    DATA_PATH = Path("data/raw") / "bank-marketing.csv"

    if DATA_PATH.exists():
        df_original = pd.read_csv(DATA_PATH)
    else:
        from ucimlrepo import fetch_ucirepo
        bank_marketing = fetch_ucirepo(id=222)
        X = bank_marketing.data.features
        y = bank_marketing.data.targets
        df_original = pd.concat([X, y], axis=1)
        DATA_PATH.parent.mkdir(parents=True, exist_ok=True)
        df_original.to_csv(DATA_PATH, index=False)
    return DATA_PATH, df_original


@app.cell
def _(DATA_PATH, df_original, mo):
    mo.vstack([
        mo.md(f"âœ… ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ: `{DATA_PATH}` ({len(df_original)} ãƒ¬ã‚³ãƒ¼ãƒ‰)"),
        mo.ui.table(df_original, page_size=10, label="å…ƒãƒ‡ãƒ¼ã‚¿ (Original Sensitive Data)"),
    ])
    return


@app.cell
def _(mo):
    mo.md(r"""
    ---

    ## Step 2: åˆæˆãƒ‡ãƒ¼ã‚¿ã®ç”Ÿæˆ

    MostlyAI SDKï¼ˆãƒ­ãƒ¼ã‚«ãƒ«ãƒ¢ãƒ¼ãƒ‰ï¼‰ã‚’ä½¿ç”¨ã—ã¦ã€å…ƒãƒ‡ãƒ¼ã‚¿ã®çµ±è¨ˆçš„ç‰¹æ€§ã‚’å­¦ç¿’ã—ã€æ–°ã—ã„åˆæˆãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆã—ã¾ã™ã€‚
    ç”Ÿæˆã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã¯å…ƒãƒ‡ãƒ¼ã‚¿ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ¨¡å€£ã—ã¾ã™ãŒã€**å®Ÿåœ¨ã™ã‚‹å€‹äººã®ãƒ‡ãƒ¼ã‚¿ã¨ã¯1å¯¾1ã§å¯¾å¿œã—ã¾ã›ã‚“**ã€‚
    """)
    return


@app.cell
def _(mo):
    sample_size_slider = mo.ui.slider(
        start=100, stop=5000, value=100, step=100,
        label="ç”Ÿæˆã™ã‚‹ã‚µãƒ³ãƒ—ãƒ«æ•°"
    )
    generate_button = mo.ui.run_button(label="åˆæˆãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ")

    mo.hstack([sample_size_slider, generate_button], justify="start", gap=1)
    return generate_button, sample_size_slider


@app.cell
def _(MostlyAI, df_original, generate_button, mo, pd, sample_size_slider):
    mo.stop(not generate_button.value, mo.md("ä¸Šã®ãƒœã‚¿ãƒ³ã‚’æŠ¼ã™ã¨åˆæˆãƒ‡ãƒ¼ã‚¿ã®ç”ŸæˆãŒå§‹ã¾ã‚Šã¾ã™ã€‚"))

    df_synthetic = pd.DataFrame()

    with mo.status.spinner("åˆæˆãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆä¸­... (ã“ã‚Œã«ã¯æ•°åˆ†ã‹ã‹ã‚‹å ´åˆãŒã‚ã‚Šã¾ã™)"):
        mostly = MostlyAI(local=True, local_dir="./mostlyai_local")
        # å„ã‚«ãƒ©ãƒ ã®ãƒ‡ãƒ¼ã‚¿å‹ã¨ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰æ–¹å¼ã‚’æ˜ç¤ºçš„ã«æŒ‡å®šã—ã¾ã™ã€‚
        # 'month' ã‚«ãƒ©ãƒ ãŒ TABULAR_DATETIME ã¨ã—ã¦èª¤èªè­˜ã•ã‚Œ Pandas ã®ã‚¨ãƒ©ãƒ¼ã«ãªã‚‹ã®ã‚’é˜²ãç›®çš„ã‚‚å…¼ã­ã¦ã„ã¾ã™ã€‚
        config = {
            'name': 'Bank Marketing',
            'tables': [
                {
                    'name': 'bank_marketing',
                    'data': df_original,
                    'tabular_model_configuration': {
                        # 'model': 'MOSTLY_AI/Medium',       # AIãƒ¢ãƒ‡ãƒ«ã®ã‚µã‚¤ã‚ºæŒ‡å®šï¼ˆSmall, Medium, Largeï¼‰
                        # 'max_epochs': 50,                  # å­¦ç¿’ã®æœ€å¤§ã‚¨ãƒãƒƒã‚¯æ•°ï¼ˆç²¾åº¦ã¨æ™‚é–“ã®ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ï¼‰
                        # 'enable_flexible_generation': True # ã‚·ãƒ¼ãƒ‰ã‚„æ¬ æå€¤è£œå®Œãªã©ã‚’æœ‰åŠ¹ã«ã™ã‚‹ã‹
                    },
                    'columns': [
                        {'name': 'age', 'model_encoding_type': 'TABULAR_NUMERIC_AUTO'},
                        {'name': 'job', 'model_encoding_type': 'TABULAR_CATEGORICAL'},
                        {'name': 'marital', 'model_encoding_type': 'TABULAR_CATEGORICAL'},
                        {'name': 'education', 'model_encoding_type': 'TABULAR_CATEGORICAL'},
                        {'name': 'default', 'model_encoding_type': 'TABULAR_CATEGORICAL'},
                        {'name': 'balance', 'model_encoding_type': 'TABULAR_NUMERIC_AUTO'},
                        {'name': 'housing', 'model_encoding_type': 'TABULAR_CATEGORICAL'},
                        {'name': 'loan', 'model_encoding_type': 'TABULAR_CATEGORICAL'},
                        {'name': 'contact', 'model_encoding_type': 'TABULAR_CATEGORICAL'},
                        {'name': 'day_of_week', 'model_encoding_type': 'TABULAR_NUMERIC_DISCRETE'},
                        {'name': 'month', 'model_encoding_type': 'TABULAR_CATEGORICAL'},
                        {'name': 'duration', 'model_encoding_type': 'TABULAR_NUMERIC_AUTO'},
                        {'name': 'campaign', 'model_encoding_type': 'TABULAR_NUMERIC_DISCRETE'},
                        {'name': 'pdays', 'model_encoding_type': 'TABULAR_NUMERIC_AUTO'},
                        {'name': 'previous', 'model_encoding_type': 'TABULAR_NUMERIC_DISCRETE'},
                        {'name': 'poutcome', 'model_encoding_type': 'TABULAR_CATEGORICAL'},
                        {'name': 'y', 'model_encoding_type': 'TABULAR_CATEGORICAL'},
                    ]
                }
            ]
        }
        g = mostly.train(config=config)
        sd = mostly.generate(g, size=sample_size_slider.value)
        df_synthetic = sd.data()

    _result = mo.vstack([
        mo.md(f"âœ… **åˆæˆãƒ‡ãƒ¼ã‚¿ã®ç”ŸæˆãŒå®Œäº†ã—ã¾ã—ãŸï¼** ({len(df_synthetic)} ãƒ¬ã‚³ãƒ¼ãƒ‰)"),
        mo.ui.table(df_synthetic, page_size=10, label="åˆæˆãƒ‡ãƒ¼ã‚¿ (Generated Synthetic Data)"),
    ])
    return df_synthetic, g, sd


@app.cell
def _(mo):
    mo.md(r"""
    ---

    ## Step 2.5: ãƒ¢ãƒ‡ãƒ«è©•ä¾¡ ("The Quality Check")

    MostlyAI ãŒè‡ªå‹•çš„ã«ç®—å‡ºã™ã‚‹ãƒ¢ãƒ‡ãƒ«å“è³ªãƒ¡ãƒˆãƒªã‚¯ã‚¹ã¨ QA ãƒ¬ãƒãƒ¼ãƒˆã‚’ç¢ºèªã—ã¾ã™ã€‚
    ã“ã‚Œã«ã‚ˆã‚Šã€ç”Ÿæˆã•ã‚ŒãŸåˆæˆãƒ‡ãƒ¼ã‚¿ãŒå…ƒãƒ‡ãƒ¼ã‚¿ã®çµ±è¨ˆçš„ç‰¹æ€§ã‚’ã©ã®ç¨‹åº¦å†ç¾ã§ãã¦ã„ã‚‹ã‹ã€
    ã¾ãŸãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼ãŒã©ã®ç¨‹åº¦ä¿è­·ã•ã‚Œã¦ã„ã‚‹ã‹ã‚’å®šé‡çš„ã«è©•ä¾¡ã§ãã¾ã™ã€‚
    """)
    return


@app.cell
def _(df_synthetic, mo, pd, sd):
    mo.stop(
        df_synthetic.empty,
        mo.md("åˆæˆãƒ‡ãƒ¼ã‚¿ãŒç”Ÿæˆã•ã‚Œã‚‹ã¨ã€ã“ã“ã«ãƒ¢ãƒ‡ãƒ«è©•ä¾¡ãƒ¡ãƒˆãƒªã‚¯ã‚¹ãŒè¡¨ç¤ºã•ã‚Œã¾ã™ã€‚")
    )

    _metrics = sd.tables[0].tabular_model_metrics

    def _fmt_pct(v):
        return f"{v * 100:.1f}%" if isinstance(v, (int, float)) else "N/A"

    def _quality_emoji(v):
        if not isinstance(v, (int, float)):
            return "â“"
        if v >= 0.9:
            return "ğŸŸ¢"
        if v >= 0.7:
            return "ğŸŸ¡"
        return "ğŸ”´"

    _acc = _metrics.accuracy if _metrics else None
    _acc_overall = _acc.overall if _acc else None
    _acc_univariate = _acc.univariate if _acc else None
    _acc_bivariate = _acc.bivariate if _acc else None

    _metrics_cards = mo.hstack(
        [
            mo.stat(
                label="Overall Accuracy",
                value=f"{_quality_emoji(_acc_overall)} {_fmt_pct(_acc_overall)}",
                bordered=True,
            ),
            mo.stat(
                label="Univariate Accuracy",
                value=f"{_quality_emoji(_acc_univariate)} {_fmt_pct(_acc_univariate)}",
                bordered=True,
            ),
            mo.stat(
                label="Bivariate Accuracy",
                value=f"{_quality_emoji(_acc_bivariate)} {_fmt_pct(_acc_bivariate)}",
                bordered=True,
            ),
        ],
        justify="center",
        gap=1,
    )

    _metrics_rows = []
    if _acc:
        for _name, _label in [
            ("overall", "Overall"), ("univariate", "Univariate"),
            ("bivariate", "Bivariate"), ("coherence", "Coherence"),
            ("overall_max", "Overall (ç†è«–ä¸Šé™)"), ("univariate_max", "Univariate (ç†è«–ä¸Šé™)"),
            ("bivariate_max", "Bivariate (ç†è«–ä¸Šé™)"),
        ]:
            _v = getattr(_acc, _name, None)
            if _v is not None:
                _metrics_rows.append({"ã‚«ãƒ†ã‚´ãƒª": "Accuracy", "ãƒ¡ãƒˆãƒªã‚¯ã‚¹": _label, "å€¤": _fmt_pct(_v)})

    _sim = _metrics.similarity if _metrics else None
    if _sim:
        for _name, _label in [
            ("cosine_similarity_training_synthetic", "Cosine (Trainâ†”Syn)"),
            ("cosine_similarity_training_holdout", "Cosine (Trainâ†”Holdout)"),
            ("discriminator_auc_training_synthetic", "Discriminator AUC (Trainâ†”Syn)"),
            ("discriminator_auc_training_holdout", "Discriminator AUC (Trainâ†”Holdout)"),
        ]:
            _v = getattr(_sim, _name, None)
            if _v is not None:
                _metrics_rows.append({"ã‚«ãƒ†ã‚´ãƒª": "Similarity", "ãƒ¡ãƒˆãƒªã‚¯ã‚¹": _label, "å€¤": _fmt_pct(_v)})

    _dist = _metrics.distances if _metrics else None
    if _dist:
        for _name, _label in [
            ("ims_training", "Identical Match (Train)"),
            ("ims_holdout", "Identical Match (Holdout)"),
            ("dcr_training", "DCR (Train)"),
            ("dcr_holdout", "DCR (Holdout)"),
        ]:
            _v = getattr(_dist, _name, None)
            if _v is not None:
                _metrics_rows.append({"ã‚«ãƒ†ã‚´ãƒª": "Distances / Privacy", "ãƒ¡ãƒˆãƒªã‚¯ã‚¹": _label, "å€¤": _fmt_pct(_v)})

    _metrics_table = mo.ui.table(
        pd.DataFrame(_metrics_rows) if _metrics_rows else pd.DataFrame({"ãƒ¡ãƒˆãƒªã‚¯ã‚¹": ["ãƒ‡ãƒ¼ã‚¿ãªã—"], "å€¤": ["-"]}),
        label="å…¨ãƒ¡ãƒˆãƒªã‚¯ã‚¹ä¸€è¦§",
    )

    mo.vstack([
        mo.md("### ğŸ“Š ãƒ¢ãƒ‡ãƒ«å“è³ªãƒ¡ãƒˆãƒªã‚¯ã‚¹"),
        _metrics_cards,
        mo.md("""
    > **Accuracy** ã¯å…ƒãƒ‡ãƒ¼ã‚¿ã®çµ±è¨ˆçš„ç‰¹æ€§ã‚’åˆæˆãƒ‡ãƒ¼ã‚¿ãŒã©ã®ç¨‹åº¦å†ç¾ã§ãã¦ã„ã‚‹ã‹ã‚’ç¤ºã—ã¾ã™ï¼ˆ`1 - TVD` ã«ç›¸å½“ï¼‰ã€‚
    > ğŸŸ¢ 90%ä»¥ä¸Š = å„ªç§€ / ğŸŸ¡ 70-90% = è‰¯å¥½ / ğŸ”´ 70%æœªæº€ = è¦æ”¹å–„
    """),
        mo.accordion({"ğŸ“‹ å…¨ãƒ¡ãƒˆãƒªã‚¯ã‚¹è©³ç´°": _metrics_table}),
    ])
    return


@app.cell
def _(Path, df_synthetic, g, mo, sd):
    import subprocess as _subprocess
    import sys as _sys
    import os as _os

    mo.stop(
        df_synthetic.empty,
        mo.md("åˆæˆãƒ‡ãƒ¼ã‚¿ãŒç”Ÿæˆã•ã‚Œã‚‹ã¨ã€ã“ã“ã« QA ãƒ¬ãƒãƒ¼ãƒˆãŒè¡¨ç¤ºã•ã‚Œã¾ã™ã€‚")
    )

    _local_dir = Path("./mostlyai_local").resolve()
    # ãƒ¦ãƒ¼ã‚¶ãƒ¼æŒ‡æ‘˜ã®é€šã‚Šã€Model QAã¯ Generator å´ã«æ ¼ç´ã•ã‚Œã¦ã„ã‚‹
    _gen_model_report_dir = _local_dir / "generators" / g.id / "ModelQAReports"
    _sd_data_report_dir = _local_dir / "synthetic-datasets" / sd.id / "DataQAReports"

    def _find_report(report_dir):
        if not report_dir.exists():
            return None
        _html_files = list(report_dir.glob("*.html"))
        return _html_files[0] if _html_files else None

    _gen_model_report = _find_report(_gen_model_report_dir)
    _sd_data_report = _find_report(_sd_data_report_dir)

    _reports = {
        "ğŸ§  Model QA": _gen_model_report,
        "ğŸ“¦ Data QA": _sd_data_report,
    }

    def _open_report(p):
        _path_str = str(p)
        if _sys.platform == "win32":
            _os.startfile(_path_str)
        else:
            _opener = "open" if _sys.platform == "darwin" else "xdg-open"
            _res = _subprocess.run([_opener, _path_str], capture_output=True, text=True)
            if _res.returncode != 0:
                print(f"âš ï¸ Failed to open {p.name}: {_res.stderr.strip()}")

    _cards = []
    for _label, _path in _reports.items():
        if _path:
            _size_mb = _path.stat().st_size / (1024 * 1024)
            _btn = mo.ui.run_button(
                label=f"{_label} ã‚’é–‹ã",
                on_change=lambda _, p=_path: _open_report(p)
            )
            _copy_text = f"`file://{_path}`"
            _cards.append(mo.vstack([
                mo.md(f"**{_label}**\n\nğŸ“„ `{_path.name}` ({_size_mb:.1f} MB)\n\n{_copy_text}"),
                _btn,
            ]))
        else:
            _cards.append(mo.md(f"**{_label}**\n\nâš ï¸ ãƒ¬ãƒãƒ¼ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚"))

    mo.vstack([
        mo.md("### ğŸ“‘ QA ãƒ¬ãƒãƒ¼ãƒˆ"),
        mo.md("> ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯ã™ã‚‹ã‹ã€è¨˜è¼‰ã® `file://...` ãƒ‘ã‚¹ã‚’ãƒ–ãƒ©ã‚¦ã‚¶ã®URLæ¬„ã«ã‚³ãƒ”ãƒ¼ï¼†ãƒšãƒ¼ã‚¹ãƒˆã—ã¦é–‹ã„ã¦ãã ã•ã„ã€‚"),
        mo.hstack(_cards, gap=1),
    ])
    return


@app.cell
def _(mo):
    mo.md(r"""
    ---

    ## Step 3: çµ±è¨ˆçš„æ¤œè¨¼ ("The Proof")

    åˆæˆãƒ‡ãƒ¼ã‚¿ãŒå…ƒãƒ‡ãƒ¼ã‚¿ã®åˆ†å¸ƒã‚’ã©ã®ç¨‹åº¦å†ç¾ã§ãã¦ã„ã‚‹ã‹ã€è¦–è¦šçš„ã«ç¢ºèªã—ã¾ã™ã€‚
    **é’è‰²**ãŒã€Œå…ƒãƒ‡ãƒ¼ã‚¿ã€ã€**èµ¤è‰²**ãŒã€Œåˆæˆãƒ‡ãƒ¼ã‚¿ã€ã§ã™ã€‚
    åˆ†å¸ƒãŒé‡ãªã£ã¦ã„ã‚‹ã»ã©ã€çµ±è¨ˆçš„æ€§è³ªãŒç¶­æŒã•ã‚Œã¦ã„ã‚‹ã“ã¨ã‚’ç¤ºã—ã¾ã™ã€‚
    """)
    return


@app.cell
def _(df_original, mo):
    columns = df_original.columns.tolist()
    column_selector = mo.ui.dropdown(
        options=columns,
        value=columns[0] if columns else None,
        label="å¯è¦–åŒ–ã™ã‚‹ã‚«ãƒ©ãƒ ã‚’é¸æŠ"
    )
    column_selector
    return (column_selector,)


@app.cell
def _(alt, column_selector, df_original, df_synthetic, mo, pd):
    mo.stop(
        df_synthetic.empty,
        mo.md("åˆæˆãƒ‡ãƒ¼ã‚¿ãŒç”Ÿæˆã•ã‚Œã‚‹ã¨ã€ã“ã“ã«æ¯”è¼ƒã‚°ãƒ©ãƒ•ãŒè¡¨ç¤ºã•ã‚Œã¾ã™ã€‚")
    )

    _col = column_selector.value

    _df_orig_plot = df_original[[_col]].copy()
    _df_orig_plot["Type"] = "Original"

    _df_syn_plot = df_synthetic[[_col]].copy()
    _df_syn_plot["Type"] = "Synthetic"

    _df_plot = pd.concat([_df_orig_plot, _df_syn_plot])

    _is_numeric = pd.api.types.is_numeric_dtype(df_original[_col])

    if _is_numeric:
        _chart = (
            alt.Chart(_df_plot)
            .mark_bar(opacity=0.5)
            .encode(
                alt.X(_col, bin=alt.Bin(maxbins=30), title=_col),
                alt.Y("count()", stack=None, title="ä»¶æ•°"),
                alt.Color(
                    "Type",
                    scale=alt.Scale(
                        domain=["Original", "Synthetic"],
                        range=["steelblue", "salmon"],
                    ),
                ),
            )
            .properties(title=f"{_col} ã®åˆ†å¸ƒæ¯”è¼ƒ", width=600, height=400)
        )
    else:
        _chart = (
            alt.Chart(_df_plot)
            .mark_bar(opacity=0.7)
            .encode(
                alt.X(_col, title=_col),
                alt.Y("count()", title="ä»¶æ•°"),
                alt.Color(
                    "Type",
                    scale=alt.Scale(
                        domain=["Original", "Synthetic"],
                        range=["steelblue", "salmon"],
                    ),
                    legend=alt.Legend(title="ãƒ‡ãƒ¼ã‚¿ç¨®åˆ¥"),
                ),
                alt.XOffset("Type"),
            )
            .properties(title=f"{_col} ã®åˆ†å¸ƒæ¯”è¼ƒ", width=600, height=400)
        )

    mo.ui.altair_chart(_chart)
    return


@app.cell
def _(mo):
    mo.md(r"""
    ---

    ## Step 4: ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼æ¤œè¨¼

    åˆæˆãƒ‡ãƒ¼ã‚¿ã®ä¸­ã‹ã‚‰ãƒ©ãƒ³ãƒ€ãƒ ã«1ã¤ã®ã‚µãƒ³ãƒ—ãƒ«ã‚’é¸ã³ã€å…ƒãƒ‡ãƒ¼ã‚¿ã®ä¸­ã§ã€Œæœ€ã‚‚ä¼¼ã¦ã„ã‚‹ã€å®Ÿåœ¨ã®äººç‰©ã‚’æ¢ã—ã¾ã™ã€‚
    ã‚‚ã—å®Œå…¨ã«ä¸€è‡´ã™ã‚‹ãƒ¬ã‚³ãƒ¼ãƒ‰ãŒå­˜åœ¨ã—ãªã‘ã‚Œã°ã€ãã‚Œã¯ã€Œæ–°ã—ã„æ¶ç©ºã®äººç‰©ã€ãŒç”Ÿæˆã•ã‚ŒãŸè¨¼æ‹ ã«ãªã‚Šã¾ã™ã€‚
    """)
    return


@app.cell
def _(NearestNeighbors, StandardScaler, df_original, df_synthetic, mo, np, pd):
    mo.stop(
        df_synthetic.empty,
        mo.md("åˆæˆãƒ‡ãƒ¼ã‚¿ãŒç”Ÿæˆã•ã‚Œã‚‹ã¨ã€ã“ã“ã«ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼æ¤œè¨¼çµæœãŒè¡¨ç¤ºã•ã‚Œã¾ã™ã€‚")
    )

    np.random.seed(None)
    _target_synthetic = df_synthetic.sample(1).iloc[0]

    _numeric_cols = df_original.select_dtypes(include=["number"]).columns.tolist()

    if not _numeric_cols:
        _out = mo.md("æ•°å€¤ã‚«ãƒ©ãƒ ãŒãªã„ãŸã‚ã€æœ€è¿‘å‚æ¢ç´¢ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã—ãŸã€‚")
    else:
        _scaler = StandardScaler()
        _X_orig = _scaler.fit_transform(df_original[_numeric_cols])
        _X_syn_sample = _scaler.transform(
            _target_synthetic[_numeric_cols].to_frame().T
        )

        _nbrs = NearestNeighbors(n_neighbors=1, algorithm="auto").fit(_X_orig)
        _distances, _indices = _nbrs.kneighbors(_X_syn_sample)

        _closest_idx = _indices[0][0]
        _closest_real = df_original.iloc[_closest_idx]

        _comparison_df = pd.DataFrame(
            {"åˆæˆãƒ‡ãƒ¼ã‚¿ (Synthetic)": _target_synthetic, "æœ€è¿‘å‚ã®å®Ÿãƒ‡ãƒ¼ã‚¿ (Real)": _closest_real}
        ).T

        _diff_msgs = []
        for _c in _numeric_cols:
            _syn_val = _target_synthetic[_c]
            _real_val = _closest_real[_c]
            if _syn_val != _real_val:
                _diff_msgs.append(f"- **{_c}**: åˆæˆ={_syn_val}, å®Ÿãƒ‡ãƒ¼ã‚¿={_real_val} (å·®: {abs(_syn_val - _real_val):.2f})")

        _diff_text = "\n".join(_diff_msgs) if _diff_msgs else "å·®åˆ†ãªã—ï¼ˆå®Œå…¨ä¸€è‡´ï¼‰"

        _out = mo.vstack([
            mo.md("### ğŸ•µï¸ æœ€è¿‘å‚æ¢ç´¢çµæœ"),
            mo.ui.table(_comparison_df, label="æ¯”è¼ƒè¡¨"),
            mo.md(f"**ãƒ¦ãƒ¼ã‚¯ãƒªãƒƒãƒ‰è·é›¢ (æ¨™æº–åŒ–å¾Œ):** {_distances[0][0]:.4f}"),
            mo.md(f"""
    **ä¸»ãªå·®åˆ†:**

    {_diff_text}

    > âœ… **çµè«–:** ä¸Šè¨˜ã®é€šã‚Šã€æœ€ã‚‚ä¼¼ã¦ã„ã‚‹å®Ÿåœ¨ãƒ‡ãƒ¼ã‚¿ã¨æ¯”è¼ƒã—ã¦ã‚‚å±æ€§å€¤ã«é•ã„ãŒã‚ã‚Šã¾ã™ã€‚
    > ã“ã‚Œã¯ã€ç”Ÿæˆã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ãŒå…ƒã®å€‹äººã®ã€Œã‚³ãƒ”ãƒ¼ã€ã§ã¯ãªãã€çµ±è¨ˆçš„ãªæ€§è³ªã‚’å—ã‘ç¶™ã„ã **æ–°ã—ã„æ¶ç©ºã®äººç‰©**ã§ã‚ã‚‹ã“ã¨ã‚’ç¤ºã—ã¦ã„ã¾ã™ã€‚
    > ã—ãŸãŒã£ã¦ã€**å†è­˜åˆ¥ãƒªã‚¹ã‚¯ã¯ä½ã„**ã¨åˆ¤æ–­ã§ãã¾ã™ã€‚
    """),
        ])

    _out
    return


if __name__ == "__main__":
    app.run()
